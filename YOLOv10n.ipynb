{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e267be-ce17-44ec-a080-7be9137b66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install ultralytics opencv-python ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02654d-914f-49ee-b9bb-b373a7a54fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35244e6f-181f-44e6-90d5-cb2c38e69fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jtop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133114d6-c886-47a7-b7b4-a919a6a8d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jtop import jtop\n",
    "\n",
    "with jtop() as jetson:\n",
    "    # jetson.ok() will provide the proper update frequency\n",
    "    while jetson.ok():\n",
    "        # Read tegra stats\n",
    "        print(jetson.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72a91d-ba73-4802-ba29-3d5005133f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import time\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Load the YOLOv10nmodel\n",
    "model = YOLO('yolov10s.pt') #load\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture('/dev/video0')\n",
    "\n",
    "# Create an output widget\n",
    "output_widget = widgets.Image()\n",
    "display(output_widget)\n",
    "\n",
    "def process_frame(frame):\n",
    "    results = model(frame)\n",
    "    annotated_frame = results[0].plot()\n",
    "    return cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def video_feed():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        processed_frame = process_frame(frame)\n",
    "        _, jpeg = cv2.imencode('.jpg', processed_frame)\n",
    "        output_widget.value = jpeg.tobytes()\n",
    "        time.sleep(0.1)  # Adjust this value to control frame rate\n",
    "\n",
    "# Start the video feed in a separate thread\n",
    "thread = threading.Thread(target=video_feed)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "# Keep the notebook running\n",
    "widgets.interactive(lambda x: x, x=widgets.IntSlider(min=1, max=10, step=1, value=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d38e9-1c8d-477c-b333-53771e829306",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdac49f-ae6d-458d-a74f-3c9f8bcd9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv10 model\n",
    "model = YOLO('yolov10s.pt')\n",
    "\n",
    "def process_video():\n",
    "    cap = cv2.VideoCapture('/dev/video0')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Perform detection\n",
    "        results = model(frame)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        yield annotated_frame\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=None,\n",
    "    outputs=\"image\",\n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(server_name=\"192.168.1.238\", server_port=7866, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab83979-f95d-4175-bab7-c33cd6acff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvgstcapture-1.0 --automate --capture-auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3e8f2-4c7b-4f69-bce0-7eacf7b3664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install jetson-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913cd69-28ec-40fd-9cab-299aa87a73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!v4l2-ctl --list-devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc3dfe-eb7f-4479-b58d-e9e374aff4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!v4l2-ctl --list-formats-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7836c01-dcbf-4ef1-b2bb-e35681687dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (nano version for lightweight performance)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# GStreamer pipeline to access the IMX219 camera at 1280x720 resolution and 60 fps\n",
    "gst_pipeline = (\n",
    "    \"nvarguscamerasrc ! \"\n",
    "    \"video/x-raw(memory:NVMM), width=1280, height=720, framerate=60/1 ! \"\n",
    "    \"nvvidconv ! video/x-raw, format=BGRx ! \"\n",
    "    \"videoconvert ! appsink\"\n",
    ")\n",
    "\n",
    "# Open the camera using the GStreamer pipeline\n",
    "cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream from the camera.\")\n",
    "    exit()\n",
    "\n",
    "# Process the video stream\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if frame was successfully captured\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to grab frame from the camera.\")\n",
    "        break\n",
    "    \n",
    "    # Perform YOLOv8 detection on the current frame\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Annotate the frame with bounding boxes\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display the frame with YOLOv8 annotations\n",
    "    cv2.imshow('YOLOv8 Object Detection', annotated_frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463e00b-f1b5-4b70-af98-ce1b8460cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
